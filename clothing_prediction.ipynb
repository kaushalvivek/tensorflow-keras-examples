{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clothing-prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD_cJRis6dUs",
        "colab_type": "text"
      },
      "source": [
        "# Clothing Prediction\n",
        "\n",
        "The following code implements a neural network to predict clothing items *(10 classes)*, using the ```fashion-mnist``` dataset for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KyjewZL8mzf",
        "colab_type": "text"
      },
      "source": [
        "### ```tensorflow-databse``` Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKRAzsjEldGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_eS6P_r8u1U",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui2qoLkjuwMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "41fb2efb-56f2-47d9-a3df-2cdd67035000"
      },
      "source": [
        "from __future__ import absolute_import,  division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tqdm\n",
        "import tqdm.auto\n",
        "tqdm.tqdm = tqdm.auto.tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRHPRLUv86tj",
        "colab_type": "text"
      },
      "source": [
        "### Loading Dataset\n",
        "\n",
        "The ```fashion_mnist``` dataset is loaded, it comprises of 70,000 images of clothing. Our model would train on these datapoints to classify clothing. The dataset is segregated into ```test``` and ```train``` segments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwmYHmhP_1n_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "14d02d26-cc11-43d4-dce5-2ea2bcc2c287"
      },
      "source": [
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "dataset_test, dataset_train = dataset['test'], dataset['train']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZEMnqthJjpk",
        "colab_type": "text"
      },
      "source": [
        "### Classes\n",
        "\n",
        "Our dataset comprises of the following 10 classes:\n",
        "- T-Shirt/Top\n",
        "- Trousers\n",
        "- Pullover\n",
        "- Dress\n",
        "- Coat\n",
        "- Sandal\n",
        "- Shirt\n",
        "- Sneaker\n",
        "- Bag\n",
        "- Ankle Boot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo9GWtPiFicH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['Tshirt/Top', 'Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ovCHYaF7RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training and test expamples saved in identifiers\n",
        "num_train = metadata.splits['train'].num_examples\n",
        "num_test = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples : \"+str(num_train)+\"\\nNumber of test examples : \"+str(num_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMQ-1DeHJ11A",
        "colab_type": "text"
      },
      "source": [
        "### Normalization Function\n",
        "\n",
        "Being an image dataset, we need to normalize our data to the 0-1 range for our learning model to work better. Hence, we create the ```normalize``` function for this task and run it over each element of our training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or7etGOAHFXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(image, labels):\n",
        "  images = tf.cast(image, tf.float32)\n",
        "  image/=255\n",
        "  return image, labels\n",
        "\n",
        "dataset_train = dataset_train.map(normalize)\n",
        "dataset_test = dataset_test.map(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrKoynn-d97U",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFapeALjKpmo",
        "colab_type": "text"
      },
      "source": [
        "Layers specified:\n",
        "- An input layer to flatten 28x28 image input to a vector.\n",
        "- A hidden layer of densely connected neurons, with the ReLU activation function.\n",
        "- An output layer with softmax as the activation functin.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ljyQG_sdg35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l0 = tf.keras.layers.Flatten(input_shape=(28,28,1))\n",
        "l1 = tf.keras.layers.Dense(512, activation = tf.nn.relu)\n",
        "l2 = tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBa6hHl8gP6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([l0,l1,l2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBLpo2LCLAFe",
        "colab_type": "text"
      },
      "source": [
        "### Model Compilation\n",
        "\n",
        "- Optimizer: ```adam```\n",
        "- Loss Function: ```sparse_categorical_crossentropy```, good results in images\n",
        "- Metrics: ```accuracy``` metric to be maximized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISDCh85Sge61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTURzMdULiIN",
        "colab_type": "text"
      },
      "source": [
        "Batch size specified, dataset randomly shuffled in batches so that the neural net doesn't learn from the order of elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpemM2yQisrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "dataset_train = dataset_train.repeat().shuffle(num_train).batch(batch_size)\n",
        "dataset_test = dataset_test.repeat().shuffle(num_test).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLWH5ofZNVZ9",
        "colab_type": "text"
      },
      "source": [
        "### Traning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLfysv0NnVeb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "77429cd6-07b9-4880-c713-72c2399ff89b"
      },
      "source": [
        "model.fit(dataset_train, epochs=10, steps_per_epoch=math.ceil(num_train/batch_size))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.4697 - acc: 0.8316\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3555 - acc: 0.8694\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3214 - acc: 0.8811\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2966 - acc: 0.8904\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2775 - acc: 0.8974\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2624 - acc: 0.9019\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2490 - acc: 0.9071\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2432 - acc: 0.9097\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2324 - acc: 0.9133\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2170 - acc: 0.9183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ead69b898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhqyJUKfrxNu",
        "colab_type": "text"
      },
      "source": [
        "### Testing Accuracy of Prdiction on Test Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prWsqXFerw5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "96aa8ba3-6c88-47b7-bdd9-06247a2b3b5d"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(dataset_test, steps=math.ceil(num_test/32))\n",
        "print(\"Accuracy on test dataset = \"+str(test_accuracy))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3464 - acc: 0.8867\n",
            "Accuracy on test dataset = 0.8866813\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}